{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9640ed3",
   "metadata": {},
   "source": [
    "# Stock Market Analysis Project\n",
    "\n",
    "**Project Description:**  \n",
    "In this project, we collected stock market data using the Yahoo Finance public API via the `yfinance` Python library.  \n",
    "The dataset includes approximately 57,500 daily records for 100 different companies between January 2023 and April 2025.  \n",
    "We engineered technical and fundamental features such as ATR, RSI, Moving Averages (MA20/MA200), P/E ratio, and Market Capitalization.  \n",
    "The goal is to perform exploratory data analysis (EDA), feature engineering, and prepare the dataset for future predictive modeling and clustering tasks.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e4b58e",
   "metadata": {},
   "source": [
    "## Data Cleaning & Feature Engineering\n",
    "\n",
    "In our project, we collected historical stock data for 100 major publicly traded companies using the `yfinance` API. The dataset includes daily price information (Open, High, Low, Close, Volume) from **January 2022 to April 2025** to ensure sufficient historical depth for accurate calculation of technical indicators.\n",
    "\n",
    "We engineered features such as **RSI (Relative Strength Index), ATR (Average True Range), MA20, and MA200** to capture key signals including volatility, momentum, and both short- and long-term trend directions. Since several indicators require a lookback period (e.g., 200 days for MA200), we deliberately extended our data collection to start a year earlier and then filtered the final dataset to include data from **January 2023** onward, ensuring reliability and stability of computed values.\n",
    "\n",
    "In addition, we enriched the dataset with **fundamental metrics** such as **P/E ratios** and **Market Capitalization**, mapped to each stock using metadata from Yahoo Finance. We also applied light formatting—rounding numerical values to three decimal places—for improved readability while preserving analytical integrity.\n",
    "\n",
    "This preprocessing pipeline ensured our data was well-structured, statistically valid, and ready for insightful exploratory analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0c6fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading historical stock data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[**********************45%                       ]  45 of 100 completed"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 19\u001b[0m\n\u001b[0;32m      5\u001b[0m tickers \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAAPL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMSFT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGOOG\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAMZN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMETA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTSLA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNVDA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBRK-B\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJPM\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJNJ\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUNH\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXOM\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPG\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHD\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCVX\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mABBV\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLLY\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMRK\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSO\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVRTX\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGM\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBDX\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFDX\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMU\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAPD\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTMUS\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     16\u001b[0m ]\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading historical stock data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43myf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtickers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtickers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2022-01-01\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2025-04-21\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1d\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_by\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mticker\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauto_adjust\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     27\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# ------------- STEP 2: Organize and concatenate data -------------\u001b[39;00m\n\u001b[0;32m     30\u001b[0m dfs \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\yfinance\\utils.py:104\u001b[0m, in \u001b[0;36mlog_indent_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntering \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m IndentationContext():\n\u001b[1;32m--> 104\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExiting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\yfinance\\multi.py:162\u001b[0m, in \u001b[0;36mdownload\u001b[1;34m(tickers, start, end, actions, threads, ignore_tz, group_by, auto_adjust, back_adjust, repair, keepna, progress, period, interval, prepost, proxy, rounding, timeout, session, multi_level_index)\u001b[0m\n\u001b[0;32m    155\u001b[0m         _download_one_threaded(ticker, period\u001b[38;5;241m=\u001b[39mperiod, interval\u001b[38;5;241m=\u001b[39minterval,\n\u001b[0;32m    156\u001b[0m                                start\u001b[38;5;241m=\u001b[39mstart, end\u001b[38;5;241m=\u001b[39mend, prepost\u001b[38;5;241m=\u001b[39mprepost,\n\u001b[0;32m    157\u001b[0m                                actions\u001b[38;5;241m=\u001b[39mactions, auto_adjust\u001b[38;5;241m=\u001b[39mauto_adjust,\n\u001b[0;32m    158\u001b[0m                                back_adjust\u001b[38;5;241m=\u001b[39mback_adjust, repair\u001b[38;5;241m=\u001b[39mrepair, keepna\u001b[38;5;241m=\u001b[39mkeepna,\n\u001b[0;32m    159\u001b[0m                                progress\u001b[38;5;241m=\u001b[39m(progress \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m), proxy\u001b[38;5;241m=\u001b[39mproxy,\n\u001b[0;32m    160\u001b[0m                                rounding\u001b[38;5;241m=\u001b[39mrounding, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shared\u001b[38;5;241m.\u001b[39m_DFS) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(tickers):\n\u001b[1;32m--> 162\u001b[0m         \u001b[43m_time\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;66;03m# download synchronously\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, ticker \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tickers):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[**********************97%********************** ]  97 of 100 completed"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# ------------- STEP 1: Download base stock data -------------\n",
    "tickers = [\n",
    "    'AAPL', 'MSFT', 'GOOG', 'AMZN', 'META', 'TSLA', 'NVDA', 'BRK-B', 'V', 'JPM',\n",
    "    'JNJ', 'UNH', 'XOM', 'PG', 'MA', 'HD', 'CVX', 'ABBV', 'LLY', 'MRK',\n",
    "    'AVGO', 'PEP', 'KO', 'COST', 'PFE', 'ADBE', 'TMO', 'WMT', 'CSCO', 'BAC',\n",
    "    'ORCL', 'MCD', 'AMD', 'ABT', 'CRM', 'DIS', 'NFLX', 'NKE', 'INTC', 'VZ',\n",
    "    'LIN', 'WFC', 'ACN', 'DHR', 'TXN', 'QCOM', 'AMGN', 'MDT', 'NEE', 'PM',\n",
    "    'UPS', 'BMY', 'MS', 'RTX', 'UNP', 'LOW', 'SPGI', 'PLD', 'IBM', 'GS',\n",
    "    'INTU', 'SBUX', 'ISRG', 'AXP', 'T', 'CAT', 'DE', 'BLK', 'GE', 'SYK',\n",
    "    'NOW', 'AMAT', 'ELV', 'CI', 'ZTS', 'CB', 'SCHW', 'ADI', 'MDLZ', 'MMC',\n",
    "    'LRCX', 'GILD', 'MO', 'PGR', 'BKNG', 'ADP', 'LMT', 'TGT', 'BA', 'USB',\n",
    "    'SO', 'C', 'VRTX', 'GM', 'BDX', 'FDX', 'MU', 'CL', 'APD', 'TMUS'\n",
    "]\n",
    "\n",
    "print(\"Downloading historical stock data...\")\n",
    "data = yf.download(\n",
    "    tickers=tickers,\n",
    "    start=\"2022-01-01\",\n",
    "    end=\"2025-04-21\",\n",
    "    interval=\"1d\",\n",
    "    group_by='ticker',\n",
    "    auto_adjust=True,\n",
    "    threads=True\n",
    ")\n",
    "\n",
    "# ------------- STEP 2: Organize and concatenate data -------------\n",
    "dfs = []\n",
    "for ticker in tickers:\n",
    "    df = data[ticker].copy()\n",
    "    df['Ticker'] = ticker\n",
    "    dfs.append(df)\n",
    "\n",
    "final_df = pd.concat(dfs)\n",
    "final_df.reset_index(inplace=True)\n",
    "\n",
    "print(\"Data has been structured successfully.\")\n",
    "\n",
    "# ------------- STEP 3: Add technical indicators -------------\n",
    "\n",
    "# ATR (Average True Range)\n",
    "high_low = final_df['High'] - final_df['Low']\n",
    "high_close = (final_df['High'] - final_df['Close'].shift()).abs()\n",
    "low_close = (final_df['Low'] - final_df['Close'].shift()).abs()\n",
    "ranges = pd.concat([high_low, high_close, low_close], axis=1)\n",
    "true_range = ranges.max(axis=1)\n",
    "final_df['ATR_14'] = true_range.ewm(span=14, adjust=False).mean()\n",
    "\n",
    "# RSI (Relative Strength Index)\n",
    "delta = final_df['Close'].diff()\n",
    "gain = delta.clip(lower=0)\n",
    "loss = -delta.clip(upper=0)\n",
    "avg_gain = gain.ewm(span=14, adjust=False).mean()\n",
    "avg_loss = loss.ewm(span=14, adjust=False).mean()\n",
    "rs = avg_gain / avg_loss\n",
    "final_df['RSI_14'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "# Replace values for initial days with insufficient data\n",
    "final_df.loc[final_df.index < 14, 'ATR_14'] = None\n",
    "final_df.loc[final_df.index < 14, 'RSI_14'] = None\n",
    "\n",
    "print(\"Technical indicators (ATR, RSI) added.\")\n",
    "\n",
    "# ------------- STEP 4: Add fundamental metrics (P/E, Market Cap) -------------\n",
    "\n",
    "print(\"Fetching fundamental data (P/E ratio, Market Cap)...\")\n",
    "\n",
    "pe_ratios = {}\n",
    "market_caps = {}\n",
    "\n",
    "for ticker in tickers:\n",
    "    stock = yf.Ticker(ticker)\n",
    "    try:\n",
    "        pe_ratios[ticker] = stock.info.get('trailingPE', None)\n",
    "        market_caps[ticker] = stock.info.get('marketCap', None)\n",
    "    except:\n",
    "        pe_ratios[ticker] = None\n",
    "        market_caps[ticker] = None\n",
    "\n",
    "final_df['P/E'] = final_df['Ticker'].map(pe_ratios)\n",
    "final_df['Market_Cap'] = final_df['Ticker'].map(market_caps)\n",
    "\n",
    "# Calculate Moving Averages\n",
    "final_df['MA20'] = final_df.groupby('Ticker')['Close'].transform(lambda x: x.rolling(window=20).mean())\n",
    "final_df['MA200'] = final_df.groupby('Ticker')['Close'].transform(lambda x: x.rolling(window=200).mean())\n",
    "\n",
    "\n",
    "print(\"Fundamental indicators added.\")\n",
    "\n",
    "# ------------- STEP 5: Save data to CSV -------------\n",
    "final_df = final_df[final_df['Date'] >= '2023-01-01']\n",
    "final_df = final_df.round(3)\n",
    "final_df.to_csv('stocks_data_full.csv', index=False)\n",
    "print(\"Data successfully saved to 'stocks_data_full.csv' with all indicators included.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c88b38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing CSV and adding Sector column...\n",
      "Sector column added successfully to 'stocks_data_full.csv'.\n"
     ]
    }
   ],
   "source": [
    "# ------------- STEP 6: Add Sector column to existing CSV -------------\n",
    "\n",
    "print(\"Loading existing CSV and adding Sector column...\")\n",
    "\n",
    "# טען את הקובץ הקיים\n",
    "df = pd.read_csv('stocks_data_full.csv')\n",
    "sectors = {\n",
    "    'AAPL': 'Technology',\n",
    "    'MSFT': 'Technology',\n",
    "    'GOOG': 'Communication Services',\n",
    "    'AMZN': 'Consumer Discretionary',\n",
    "    'META': 'Communication Services',\n",
    "    'TSLA': 'Consumer Discretionary',\n",
    "    'NVDA': 'Technology',\n",
    "    'BRK-B': 'Financials',\n",
    "    'V': 'Technology',\n",
    "    'JPM': 'Financials',\n",
    "    'JNJ': 'Health Care',\n",
    "    'UNH': 'Health Care',\n",
    "    'XOM': 'Energy',\n",
    "    'PG': 'Consumer Staples',\n",
    "    'MA': 'Technology',\n",
    "    'HD': 'Consumer Discretionary',\n",
    "    'CVX': 'Energy',\n",
    "    'ABBV': 'Health Care',\n",
    "    'LLY': 'Health Care',\n",
    "    'MRK': 'Health Care',\n",
    "    'AVGO': 'Technology',\n",
    "    'PEP': 'Consumer Staples',\n",
    "    'KO': 'Consumer Staples',\n",
    "    'COST': 'Consumer Staples',\n",
    "    'PFE': 'Health Care',\n",
    "    'ADBE': 'Technology',\n",
    "    'TMO': 'Health Care',\n",
    "    'WMT': 'Consumer Staples',\n",
    "    'CSCO': 'Technology',\n",
    "    'BAC': 'Financials',\n",
    "    'ORCL': 'Technology',\n",
    "    'MCD': 'Consumer Discretionary',\n",
    "    'AMD': 'Technology',\n",
    "    'ABT': 'Health Care',\n",
    "    'CRM': 'Technology',\n",
    "    'DIS': 'Communication Services',\n",
    "    'NFLX': 'Communication Services',\n",
    "    'NKE': 'Consumer Discretionary',\n",
    "    'INTC': 'Technology',\n",
    "    'VZ': 'Communication Services',\n",
    "    'LIN': 'Materials',\n",
    "    'WFC': 'Financials',\n",
    "    'ACN': 'Technology',\n",
    "    'DHR': 'Health Care',\n",
    "    'TXN': 'Technology',\n",
    "    'QCOM': 'Technology',\n",
    "    'AMGN': 'Health Care',\n",
    "    'MDT': 'Health Care',\n",
    "    'NEE': 'Utilities',\n",
    "    'PM': 'Consumer Staples',\n",
    "    'UPS': 'Industrials',\n",
    "    'BMY': 'Health Care',\n",
    "    'MS': 'Financials',\n",
    "    'RTX': 'Industrials',\n",
    "    'UNP': 'Industrials',\n",
    "    'LOW': 'Consumer Discretionary',\n",
    "    'SPGI': 'Financials',\n",
    "    'PLD': 'Real Estate',\n",
    "    'IBM': 'Technology',\n",
    "    'GS': 'Financials',\n",
    "    'INTU': 'Technology',\n",
    "    'SBUX': 'Consumer Discretionary',\n",
    "    'ISRG': 'Health Care',\n",
    "    'AXP': 'Financials',\n",
    "    'T': 'Communication Services',\n",
    "    'CAT': 'Industrials',\n",
    "    'DE': 'Industrials',\n",
    "    'BLK': 'Financials',\n",
    "    'GE': 'Industrials',\n",
    "    'SYK': 'Health Care',\n",
    "    'NOW': 'Technology',\n",
    "    'AMAT': 'Technology',\n",
    "    'ELV': 'Health Care',\n",
    "    'CI': 'Health Care',\n",
    "    'ZTS': 'Health Care',\n",
    "    'CB': 'Financials',\n",
    "    'SCHW': 'Financials',\n",
    "    'ADI': 'Technology',\n",
    "    'MDLZ': 'Consumer Staples',\n",
    "    'MMC': 'Financials',\n",
    "    'LRCX': 'Technology',\n",
    "    'GILD': 'Health Care',\n",
    "    'MO': 'Consumer Staples',\n",
    "    'PGR': 'Financials',\n",
    "    'BKNG': 'Consumer Discretionary',\n",
    "    'ADP': 'Industrials',\n",
    "    'LMT': 'Industrials',\n",
    "    'TGT': 'Consumer Staples',\n",
    "    'BA': 'Industrials',\n",
    "    'USB': 'Financials',\n",
    "    'SO': 'Utilities',\n",
    "    'C': 'Financials',\n",
    "    'VRTX': 'Health Care',\n",
    "    'GM': 'Consumer Discretionary',\n",
    "    'BDX': 'Health Care',\n",
    "    'FDX': 'Industrials',\n",
    "    'MU': 'Technology',\n",
    "    'CL': 'Consumer Staples',\n",
    "    'APD': 'Materials',\n",
    "    'TMUS': 'Communication Services'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "df['Sector'] = df['Ticker'].map(sectors)\n",
    "df.to_csv('stocks_data_full.csv', index=False)\n",
    "print(\"Sector column added successfully to 'stocks_data_full.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
